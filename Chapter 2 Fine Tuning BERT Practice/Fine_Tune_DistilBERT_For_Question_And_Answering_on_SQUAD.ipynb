{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune BERT For Question And Answering on SQUAD\n",
        "Author: Nelson LIN (nelsonlin0321@outlook.com)"
      ],
      "metadata": {
        "id": "MoZ-3s0mN4JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libaries\n",
        "import torch\n",
        "from torch import cuda\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "drMVKL8eN5oS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "fTq-NCOvOFFD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "Eyjlx0JdOX2n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import default_data_collator"
      ],
      "metadata": {
        "id": "qiBbyLVoON3Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "G4uhX374OVlZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name =  \"distilbert-base-uncased\""
      ],
      "metadata": {
        "id": "6V0arb4xkvG-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Import Data\n",
        "\n"
      ],
      "metadata": {
        "id": "wQyjnbikOrKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID2vfxSqOvC6",
        "outputId": "2ddf2d23-1b66-4340-98c5-104b5ad545c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squad_v2_dir = \"/content/drive/My Drive/Colab Notebooks/Data/SQUAD2\" # data folder"
      ],
      "metadata": {
        "id": "OEtzG5rUPp6p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(squad_v2_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg-lRCu6Vieo",
        "outputId": "15031425-ae85-471d-c6ed-8cf72248a71e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train-v2.0.json', 'dev-v2.0.json', 'evaluate.py', '__pycache__']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "include_impossible = False\n",
        "load_impossible_answer = False"
      ],
      "metadata": {
        "id": "Vz4NCqt9QB47"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download from https://rajpurkar.github.io/SQuAD-explorer/\n",
        "train_data_path = os.path.join(squad_v2_dir,\"train-v2.0.json\")\n",
        "dev_data_path = os.path.join(squad_v2_dir,'dev-v2.0.json')"
      ],
      "metadata": {
        "id": "DjhI7BbmQK6R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json(file_path):\n",
        "    with open(file_path) as f:\n",
        "        json_f = json.load(f)\n",
        "    data = json_f['data']\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "Y0ym141PQbkh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_index(List):\n",
        "    return random.sample(range(len(List)),1)[0]"
      ],
      "metadata": {
        "id": "4Aup16SKQpTi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_path, load_impossible_answer = False):\n",
        "\n",
        "    data = read_json(data_path)\n",
        "    \n",
        "    data_dict = {}\n",
        "    title_list = []\n",
        "    context_list = []\n",
        "    question_list = []\n",
        "    id_list = []\n",
        "    answer_text_list = []\n",
        "    answer_start_list = []\n",
        "    is_impossible_list = []\n",
        "    \n",
        "    for paragraphs in data:\n",
        "        title = paragraphs['title']\n",
        "        context_qas_list = paragraphs['paragraphs']\n",
        "\n",
        "        for context_qas in context_qas_list:\n",
        "            context = context_qas['context']\n",
        "            qas_list = context_qas['qas']\n",
        "\n",
        "            for qas in qas_list:\n",
        "                title_list.append(title)\n",
        "                context_list.append(context)\n",
        "\n",
        "                is_impossible = qas['is_impossible']\n",
        "                is_impossible_list.append(is_impossible)\n",
        "\n",
        "                id_ = qas['id']\n",
        "                id_list.append(id_)\n",
        "                question = qas['question']\n",
        "                question_list.append(question)\n",
        "\n",
        "                if not is_impossible:\n",
        "                    answer_list = qas['answers']\n",
        "                    idx = get_random_index(answer_list)\n",
        "                    answer_text = answer_list[idx]['text']\n",
        "                    answer_start = answer_list[idx]['answer_start']\n",
        "\n",
        "                    answer_text_list.append(answer_text)\n",
        "                    answer_start_list.append(answer_start)\n",
        "                else:\n",
        "                    if load_impossible_answer:\n",
        "                        answer_list = qas['plausible_answers']\n",
        "                        idx = get_random_index(answer_list)\n",
        "                        answer_text = answer_list[idx]['text']\n",
        "                        answer_start = answer_list[idx]['answer_start']\n",
        "                        answer_text_list.append(answer_text)\n",
        "                        answer_start_list.append(answer_start)\n",
        "                    else:\n",
        "                        answer_text_list.append(\"\")\n",
        "                        answer_start_list.append(-1)\n",
        "\n",
        "    data_dict['id'] = id_list\n",
        "    data_dict['title'] = title_list\n",
        "    data_dict['context'] = context_list\n",
        "    data_dict['question'] = question_list\n",
        "    data_dict['answer_text'] = answer_text_list\n",
        "    data_dict['answer_start'] = answer_start_list\n",
        "    data_dict['is_impossible'] = is_impossible_list\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DFr9bUauQwhh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 8000\n",
        "# take the sample size for training only"
      ],
      "metadata": {
        "id": "5iy6W_W0VCHK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dict = load_data(train_data_path,load_impossible_answer=False)\n",
        "dev_data_dict = load_data(dev_data_path,load_impossible_answer=False)"
      ],
      "metadata": {
        "id": "kpjr1_H6VB78"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df = pd.DataFrame(train_data_dict)\n",
        "dev_data_df = pd.DataFrame(dev_data_dict)"
      ],
      "metadata": {
        "id": "aHNm1MbrWDqD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not include_impossible:\n",
        "    train_data_df = train_data_df[train_data_df['is_impossible']==False]\n",
        "    dev_data_df = dev_data_df[dev_data_df['is_impossible']==False]\n",
        "\n",
        "train_data_df = shuffle(train_data_df).head(sample_size)\n",
        "dev_data_df = dev_data_df.head(sample_size)"
      ],
      "metadata": {
        "id": "ewvSqSEDWLmR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "trc2dP2oW0xX",
        "outputId": "107237d1-5d37-4404-d9a2-08291c4569e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4c6a704f-dd4f-4e87-847e-9d06923bc9d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7819</th>\n",
              "      <td>56dc7e6714d3a41400c26922</td>\n",
              "      <td>Comprehensive_school</td>\n",
              "      <td>Scotland has a very different educational syst...</td>\n",
              "      <td>What has Scotland refused to adopt?</td>\n",
              "      <td>specialist schools</td>\n",
              "      <td>345</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55195</th>\n",
              "      <td>5726420638643c19005ad3a1</td>\n",
              "      <td>Mammal</td>\n",
              "      <td>To maintain a high constant body temperature i...</td>\n",
              "      <td>What do the majority of mammals under 18 oz eat?</td>\n",
              "      <td>insects</td>\n",
              "      <td>1674</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103995</th>\n",
              "      <td>572eb7eddfa6aa1500f8d309</td>\n",
              "      <td>Spanish_language_in_the_United_States</td>\n",
              "      <td>Until the 20th century, there was no clear rec...</td>\n",
              "      <td>When did the Venezuelans emigrate to the unite...</td>\n",
              "      <td>Until the 20th century, there was no clear rec...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104451</th>\n",
              "      <td>5730462ba23a5019007fd047</td>\n",
              "      <td>Charleston,_South_Carolina</td>\n",
              "      <td>As many as five bands were on tour during the ...</td>\n",
              "      <td>When did Gershwin and Heyward write their folk...</td>\n",
              "      <td>summer of 1934</td>\n",
              "      <td>722</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38964</th>\n",
              "      <td>570c347e6b8089140040fc36</td>\n",
              "      <td>Federal_Bureau_of_Investigation</td>\n",
              "      <td>The FBI has been frequently depicted in popula...</td>\n",
              "      <td>When did the FBI first appear in popular media?</td>\n",
              "      <td>1930s</td>\n",
              "      <td>64</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c6a704f-dd4f-4e87-847e-9d06923bc9d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c6a704f-dd4f-4e87-847e-9d06923bc9d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c6a704f-dd4f-4e87-847e-9d06923bc9d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                              id  ... is_impossible\n",
              "7819    56dc7e6714d3a41400c26922  ...         False\n",
              "55195   5726420638643c19005ad3a1  ...         False\n",
              "103995  572eb7eddfa6aa1500f8d309  ...         False\n",
              "104451  5730462ba23a5019007fd047  ...         False\n",
              "38964   570c347e6b8089140040fc36  ...         False\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tsZsSgm3Wwmo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Label Preparation / Feature Engineering"
      ],
      "metadata": {
        "id": "xazR7eZpXcZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512"
      ],
      "metadata": {
        "id": "N61l98MhbURZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "e5DLd3b3aqde"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to search the start and end position for labeling\n",
        "\n",
        "def search_start_end_position(tokenized_inputs,start_char,answer_text):\n",
        "\n",
        "    offsets = tokenized_inputs.pop(\"offset_mapping\")\n",
        "\n",
        "    end_char = start_char + len(answer_text)\n",
        "\n",
        "    token_start_index = 0\n",
        "    sequence_ids = tokenized_inputs.sequence_ids()\n",
        "\n",
        "    while sequence_ids[token_start_index]!=1:\n",
        "        token_start_index +=1\n",
        "    \n",
        "    token_end_index = len(tokenized_inputs)-1\n",
        "    while sequence_ids[token_end_index] != 1:\n",
        "        token_end_index -=1\n",
        "\n",
        "    if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "\n",
        "        while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "            token_start_index+=1\n",
        "        \n",
        "        start_position = token_start_index - 1\n",
        "\n",
        "        while offsets[token_end_index][1] >= end_char:\n",
        "            token_end_index -=1\n",
        "        \n",
        "        end_position = token_end_index + 1\n",
        "        \n",
        "        end_position = len(sequence_ids) + end_position\n",
        "\n",
        "        return start_position,end_position\n",
        "\n",
        "    return -1,-1\n",
        "\n"
      ],
      "metadata": {
        "id": "UQ3INq7LXkgN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"test\"\"\"\n",
        "example_id = 0\n",
        "example = train_data_df.iloc[example_id]\n",
        "\n",
        "context = example['context']\n",
        "question = example['question']\n",
        "answer_text = example['answer_text']\n",
        "start_char = example['answer_start']"
      ],
      "metadata": {
        "id": "ITS3R3yWZjO7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_inputs = tokenizer(\n",
        "    text = question,\n",
        "    text_pair = context,\n",
        "    truncation = \"only_second\",\n",
        "    add_special_tokens = True,\n",
        "    max_length = max_length,\n",
        "    padding = \"max_length\",\n",
        "    return_offsets_mapping = True,\n",
        ")"
      ],
      "metadata": {
        "id": "wDPnc4gcakSo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y-2zdJsbt4f",
        "outputId": "16ce7556-f0ee-49e0-dd8f-c08e1601664a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_pos,end_pos = search_start_end_position(tokenized_inputs,start_char,answer_text)"
      ],
      "metadata": {
        "id": "jOZwaUSnbZFw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_pos,end_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7InfXcvdvAt",
        "outputId": "9724874b-d780-4912-d9ab-35be44c39b33"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(63, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JBQAWs_qc-1g",
        "outputId": "bc61efaa-3ed2-4a78-8db5-96427aad0de3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'specialist schools'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenized_inputs['input_ids'][start_pos:end_pos+1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Hb8XT2c8Ly",
        "outputId": "3d2be109-717d-4d5d-b485-17146aa3b91c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "specialist schools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare feature for model feeding\n",
        "\n",
        "def prepare_feature(example):\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "    answer_text = example['answer_text']\n",
        "    start_char = example['answer_start']\n",
        "\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text = question,\n",
        "        text_pair = context,\n",
        "        truncation = \"only_second\",\n",
        "        add_special_tokens = True,\n",
        "        max_length = max_length,\n",
        "        padding = \"max_length\",\n",
        "        return_offsets_mapping = True,\n",
        "    )\n",
        "\n",
        "    cls_index = tokenized_inputs['input_ids'].index(tokenizer.cls_token_id)\n",
        "\n",
        "    if start_char ==-1:\n",
        "        tokenized_inputs['start_positions'] = cls_index\n",
        "        tokenized_inputs['end_positions'] = cls_index\n",
        "        _ = tokenized_inputs.pop(\"offset_mapping\")\n",
        "    else:\n",
        "        start_pos,end_pos = search_start_end_position(tokenized_inputs,start_char,answer_text)\n",
        "        if start_pos!=-1 and end_pos!=-1:\n",
        "            tokenized_inputs['start_positions'] = start_pos\n",
        "            tokenized_inputs['end_positions'] = end_pos\n",
        "        else:\n",
        "            tokenized_inputs['start_positions'] = cls_index\n",
        "            tokenized_inputs['end_positions'] = cls_index\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_mU8Jpb9dH1S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_feature(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKsvzQ1Pey0x",
        "outputId": "9317e9eb-01d8-4444-da16-bca201032d8a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2054, 2038, 3885, 4188, 2000, 11092, 1029, 102, 3885, 2038, 1037, 2200, 2367, 4547, 2291, 2013, 2563, 1998, 3575, 1010, 2295, 2036, 2241, 2006, 7721, 2495, 1012, 2009, 2038, 2367, 5535, 1997, 4651, 1010, 2367, 14912, 1998, 1037, 2367, 4695, 1997, 3601, 1998, 9347, 1012, 2035, 7271, 6787, 3078, 1998, 3905, 2816, 2024, 7721, 1012, 1996, 4104, 2231, 2038, 5837, 3488, 2005, 8325, 2816, 2004, 1997, 2384, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 63, 'end_positions': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Test\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4JaHtpqEgN0p",
        "outputId": "d8b3de8c-60f3-4d6c-adb3-f23fa8faa1b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Test'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_train_data_df  = train_data_df.head(5)\n",
        "train_features_temp = sample_train_data_df.apply(lambda df:prepare_feature(df),axis = 1)"
      ],
      "metadata": {
        "id": "l40V3DyLgpJJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample = pd.DataFrame(list(train_features_temp))"
      ],
      "metadata": {
        "id": "KhbhHGWUg654"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "_GQjlTUFg4VZ",
        "outputId": "53fb9c0d-d0bb-4101-b4d5-24b96ec4e9c0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2736e622-1f87-4423-95aa-dc89ee937d6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>end_positions</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>start_positions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>64</td>\n",
              "      <td>[101, 2054, 2038, 3885, 4188, 2000, 11092, 102...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>371</td>\n",
              "      <td>[101, 2054, 2079, 1996, 3484, 1997, 11993, 210...</td>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>36</td>\n",
              "      <td>[101, 2043, 2106, 1996, 15332, 2015, 12495, 22...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>164</td>\n",
              "      <td>[101, 2043, 2106, 25600, 1998, 4931, 7652, 433...</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[101, 2043, 2106, 1996, 8495, 2034, 3711, 1999...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2736e622-1f87-4423-95aa-dc89ee937d6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2736e622-1f87-4423-95aa-dc89ee937d6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2736e622-1f87-4423-95aa-dc89ee937d6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      attention_mask  ...  start_positions\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               63\n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...              371\n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               14\n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...              162\n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               23\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_answer(df):\n",
        "    return tokenizer.decode(df[\"input_ids\"][df['start_positions']:df['end_positions']+1])"
      ],
      "metadata": {
        "id": "ekosjUMnhA5M"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = sample.apply(lambda x:decode_answer(x),axis = 1)"
      ],
      "metadata": {
        "id": "XP94u-bWhS5S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_b15WgYhjJw",
        "outputId": "ce25705a-5e86-4d83-ca78-17390dd9ac22"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                   specialist schools\n",
              "1                                              insects\n",
              "2    until the 20th century, there was no clear rec...\n",
              "3                                       summer of 1934\n",
              "4                                                1930s\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_train_data_df['answer_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afper71bhoUW",
        "outputId": "93d8767e-166a-40bf-c9d9-03eb16057e7e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7819                                     specialist schools\n",
              "55195                                               insects\n",
              "103995    Until the 20th century, there was no clear rec...\n",
              "104451                                       summer of 1934\n",
              "38964                                                 1930s\n",
              "Name: answer_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### convert to data frame dataset"
      ],
      "metadata": {
        "id": "RCdyJJoRhsyu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_feature_df = train_data_df.apply(lambda df: prepare_feature(df),axis = 1)\n",
        "train_feature_df = pd.DataFrame(list(train_feature_df))\n",
        "\n",
        "\n",
        "dev_feature_df = dev_data_df.apply(lambda df: prepare_feature(df),axis = 1)\n",
        "dev_feature_df = pd.DataFrame(list(dev_feature_df))"
      ],
      "metadata": {
        "id": "K1DNPAA3izBB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dev_feature_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "bxOacmGhjI3Q",
        "outputId": "63963957-05ec-4729-b326-93dfbd3c19ee"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9ecfce78-2b04-45f6-8d21-c5ec3e517bab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>end_positions</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>start_positions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>49</td>\n",
              "      <td>[101, 1999, 2054, 2406, 2003, 13298, 2284, 102...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>40</td>\n",
              "      <td>[101, 2043, 2020, 1996, 5879, 2015, 1999, 1329...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>76</td>\n",
              "      <td>[101, 2013, 2029, 3032, 2106, 1996, 15342, 217...</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>81</td>\n",
              "      <td>[101, 2040, 2001, 1996, 15342, 3003, 1029, 102...</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>158</td>\n",
              "      <td>[101, 2054, 2301, 2106, 1996, 5879, 2015, 2034...</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ecfce78-2b04-45f6-8d21-c5ec3e517bab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ecfce78-2b04-45f6-8d21-c5ec3e517bab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ecfce78-2b04-45f6-8d21-c5ec3e517bab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      attention_mask  ...  start_positions\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               49\n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               35\n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               72\n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...               80\n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...              157\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### create pytorch dataset"
      ],
      "metadata": {
        "id": "OWabs7K2jFd3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SQUADTokenizedDataSet(Dataset):\n",
        "    def __init__(self,dataframe,device = \"cpu\"):\n",
        "        self.len = len(dataframe)\n",
        "        self.dataframe = dataframe\n",
        "        self.device = device\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        df = self.dataframe.iloc[index]\n",
        "\n",
        "        if isinstance(df,pd.core.series.Series):\n",
        "            data_dict = df.to_dict()\n",
        "        else:\n",
        "            data_dict = df.to_dict(orient = \"list\")\n",
        "\n",
        "        return {k:torch.tensor(v,dtype = torch.long).to(self.device) for k,v in data_dict.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "BB4r6TBHjOkY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTokenizedDataset  = SQUADTokenizedDataSet(train_feature_df,\"cpu\")\n",
        "DevTokenizedDataset  = SQUADTokenizedDataSet(dev_feature_df,\"cpu\")"
      ],
      "metadata": {
        "id": "o5HaoHEkkGBX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Fine Tune Model"
      ],
      "metadata": {
        "id": "Xr-KMJe2kXd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForQuestionAnswering,TrainingArguments,Trainer,BertForQuestionAnswering"
      ],
      "metadata": {
        "id": "MPleHKzykMzS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForQuestionAnswering.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlsg5ptvklxA",
        "outputId": "59661528-b85f-4cf3-f395-b027229bd926"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "source codes from transformer\n",
        "```python\n",
        "class BertForQuestionAnswering(BertPreTrainedModel):\n",
        "\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.bert = BertModel(config, add_pooling_layer=False)\n",
        "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
        "    @add_code_sample_docstrings(\n",
        "        processor_class=_TOKENIZER_FOR_DOC,\n",
        "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
        "        output_type=QuestionAnsweringModelOutput,\n",
        "        config_class=_CONFIG_FOR_DOC,\n",
        "    )\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        start_positions=None,\n",
        "        end_positions=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        start_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence\n",
        "            are not taken into account for computing the loss.\n",
        "        end_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence\n",
        "            are not taken into account for computing the loss.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        logits = self.qa_outputs(sequence_output)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1).contiguous()\n",
        "        end_logits = end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        total_loss = None\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            # If we are on multi-GPU, split add a dimension\n",
        "            if len(start_positions.size()) > 1:\n",
        "                start_positions = start_positions.squeeze(-1)\n",
        "            if len(end_positions.size()) > 1:\n",
        "                end_positions = end_positions.squeeze(-1)\n",
        "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
        "            ignored_index = start_logits.size(1)\n",
        "            start_positions = start_positions.clamp(0, ignored_index)\n",
        "            end_positions = end_positions.clamp(0, ignored_index)\n",
        "\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
        "            start_loss = loss_fct(start_logits, start_positions)\n",
        "            end_loss = loss_fct(end_logits, end_positions)\n",
        "            total_loss = (start_loss + end_loss) / 2\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (start_logits, end_logits) + outputs[2:]\n",
        "            return ((total_loss,) + output) if total_loss is not None else output\n",
        "\n",
        "        return QuestionAnsweringModelOutput(\n",
        "            loss=total_loss,\n",
        "            start_logits=start_logits,\n",
        "            end_logits=end_logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qVaJXUTVlJAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_data = TrainTokenizedDataset[:5]"
      ],
      "metadata": {
        "id": "CERY_suak0zh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model(**sample_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEZH2MYklZTg",
        "outputId": "3a2999a0-2083-485a-d589-61d11b8d6f50"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput([('loss', tensor(6.2595, grad_fn=<DivBackward0>)),\n",
              "                              ('start_logits',\n",
              "                               tensor([[-0.1945,  0.0443, -0.0266,  ...,  0.1642,  0.1491,  0.1103],\n",
              "                                       [-0.1292,  0.1695,  0.1493,  ...,  0.1701,  0.2677,  0.1699],\n",
              "                                       [-0.0270,  0.0928,  0.2349,  ...,  0.1643,  0.2820,  0.2661],\n",
              "                                       [-0.1232,  0.0354,  0.0747,  ...,  0.1404,  0.1157,  0.1383],\n",
              "                                       [-0.0149,  0.0599,  0.1335,  ...,  0.3116,  0.2690,  0.2174]],\n",
              "                                      grad_fn=<CloneBackward0>)),\n",
              "                              ('end_logits',\n",
              "                               tensor([[ 0.0603,  0.2172,  0.0854,  ..., -0.1009, -0.0850, -0.0702],\n",
              "                                       [ 0.1477,  0.2885,  0.2669,  ...,  0.1825,  0.3170,  0.1020],\n",
              "                                       [ 0.0085, -0.2244, -0.0996,  ..., -0.0086, -0.0091,  0.0295],\n",
              "                                       [ 0.2466, -0.1480,  0.0937,  ..., -0.0012, -0.0442, -0.1195],\n",
              "                                       [ 0.2136, -0.1260, -0.0654,  ...,  0.2773,  0.0769,  0.0784]],\n",
              "                                      grad_fn=<CloneBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"/content/drive/My Drive/Colab Notebooks/Models/SQUADModels\" # data folder"
      ],
      "metadata": {
        "id": "0GdygaXwli_7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOagz0qTmHCH",
        "outputId": "166ff47e-057e-47c9-f634-1eb55b001003"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runs']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 12"
      ],
      "metadata": {
        "id": "Ef-nm-CDmjrf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir = model_save_path,\n",
        "    overwrite_output_dir = True,\n",
        "    do_train  = True,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    num_train_epochs = 2,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    learning_rate = 2e-5,\n",
        "    weight_decay = 0.01,\n",
        "    logging_steps = 64,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9QvYCpMlbx4",
        "outputId": "e5799dc1-a44a-4247-fa80-1507dc2566d6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = default_data_collator"
      ],
      "metadata": {
        "id": "nONu_Kyfm0fW"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "model,\n",
        "args,\n",
        "train_dataset = TrainTokenizedDataset,\n",
        "eval_dataset = DevTokenizedDataset,\n",
        "data_collator = data_collator,\n",
        "tokenizer = tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "XITuziM-m6HX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "vwZUB7S0nMBH",
        "outputId": "274b46bb-ec8a-4b3e-ceb6-4675a1ecca50"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 8000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 12\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1334\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1334' max='1334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1334/1334 16:48, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.872700</td>\n",
              "      <td>1.763241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.464700</td>\n",
              "      <td>1.663530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-500\n",
            "Configuration saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-500/config.json\n",
            "Model weights saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5928\n",
            "  Batch size = 12\n",
            "Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-1000\n",
            "Configuration saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/My Drive/Colab Notebooks/Models/SQUADModels/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5928\n",
            "  Batch size = 12\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1334, training_loss=1.9241173842857624, metrics={'train_runtime': 1009.3521, 'train_samples_per_second': 15.852, 'train_steps_per_second': 1.322, 'total_flos': 2090449600512000.0, 'train_loss': 1.9241173842857624, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "eCNlKD0PoA8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_inputs = TrainTokenizedDataset[30:35]\n",
        "token_inputs = {k:v.to(device) for k,v in token_inputs.items()}\n",
        "max_answer_len = 32"
      ],
      "metadata": {
        "id": "UuSI48GNn7aQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_from_tokenized_inputs(model,token_inputs,device = 'cude'):\n",
        "    token_inputs = {k:v.to(device) for k,v in token_inputs.items()}\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(**token_inputs)\n",
        "\n",
        "\n",
        "    token_inputs = {k:v.to(\"cpu\") for k,v in token_inputs.items()}\n",
        "\n",
        "    start_logits = output.start_logits.cpu().detach().numpy()\n",
        "    end_logits = output.end_logits.cpu().detach().numpy()\n",
        "\n",
        "    input_ids = token_inputs['input_ids']\n",
        "    result_dict_list = []\n",
        "\n",
        "    for idx in range(len(start_logits)):\n",
        "        result_dict = {}\n",
        "        start_end = (0,0)\n",
        "        start_end_score = (-1,-1)\n",
        "\n",
        "        score = -1\n",
        "\n",
        "        for start,p_start in enumerate(start_logits[idx]):\n",
        "            if p_start>0:\n",
        "                for end,p_end in enumerate(end_logits[idx]):\n",
        "                    if p_end>0:\n",
        "                        if end >= start and end < start + max_answer_len:\n",
        "                            if p_start * p_end > score:\n",
        "                                start_end = (start,end)\n",
        "                                start_end_score = (p_start,p_end)\n",
        "                                score = p_start * p_end\n",
        "        start,end = start_end\n",
        "        start_score,end_score = start_end_score\n",
        "\n",
        "        pred_answer = \"\"\n",
        "        if start!=0 and end !=0:\n",
        "            pred_answer = tokenizer.decode(\n",
        "                input_ids[idx][start:end+1]\n",
        "            )\n",
        "\n",
        "        result_dict['start_pos'] = start\n",
        "        result_dict['start_score'] = start_score\n",
        "        result_dict['end_pos'] = end\n",
        "        result_dict['end_score'] = end_score\n",
        "\n",
        "        result_dict['answer'] = pred_answer\n",
        "        result_dict['score'] = score\n",
        "\n",
        "        result_dict_list.append(result_dict)\n",
        "\n",
        "    return result_dict_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "3Qk6jeB_pQgH"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# answer_question_from_tokenized_inputs(model,token_inputs,'cuda')"
      ],
      "metadata": {
        "id": "SZ3ncEC-r0vg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_from_context(context_list,question_list,tokenizer,device):\n",
        "    tokenized_list = []\n",
        "\n",
        "    for context,question in zip(context_list,question_list):\n",
        "        tokenized_inputs = tokenizer(\n",
        "            text = question,\n",
        "            text_pair = context,\n",
        "            truncation = \"only_second\",\n",
        "            add_special_tokens = True,\n",
        "            max_length = max_length,\n",
        "            padding = \"max_length\",\n",
        "            return_offsets_mapping = False,\n",
        "        )\n",
        "\n",
        "        tokenized_list.append(tokenized_inputs)\n",
        "\n",
        "\n",
        "    tokenized_dataframe = pd.DataFrame(tokenized_list)\n",
        "\n",
        "    token_inputs = tokenized_dataframe.to_dict(\"list\")\n",
        "\n",
        "    token_inputs = {k:torch.tensor(v,dtype = torch.long).to(device) for k,v in token_inputs.items()}\n",
        "\n",
        "    res_list = answer_question_from_tokenized_inputs(model,token_inputs,device = device)\n",
        "\n",
        "    return res_list"
      ],
      "metadata": {
        "id": "wakfPK77r9wS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = train_data_df.head(5)\n",
        "context_list = sample_df['context']\n",
        "question_list = sample_df['question']\n",
        "real_answer_list = sample_df['answer_text']"
      ],
      "metadata": {
        "id": "V8aNWoWgtc5w"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result = answer_question_from_context(context_list,question_list,tokenizer,'cuda')"
      ],
      "metadata": {
        "id": "9yu0Qudutwkj"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RnnjS39t3II",
        "outputId": "704e0fbb-776f-47db-fad7-88526ec4bffc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': 'specialist schools',\n",
              "  'end_pos': 64,\n",
              "  'end_score': 2.3163822,\n",
              "  'score': 6.4470944,\n",
              "  'start_pos': 63,\n",
              "  'start_score': 2.7832603},\n",
              " {'answer': '500 g',\n",
              "  'end_pos': 365,\n",
              "  'end_score': 4.0800505,\n",
              "  'score': 11.167816,\n",
              "  'start_pos': 364,\n",
              "  'start_score': 2.737176},\n",
              " {'answer': '18th and early 19th centuries',\n",
              "  'end_pos': 43,\n",
              "  'end_score': 2.041257,\n",
              "  'score': 5.43066,\n",
              "  'start_pos': 39,\n",
              "  'start_score': 2.660449},\n",
              " {'answer': '1934',\n",
              "  'end_pos': 164,\n",
              "  'end_score': 6.2909193,\n",
              "  'score': 30.055708,\n",
              "  'start_pos': 164,\n",
              "  'start_score': 4.7776337},\n",
              " {'answer': 'the 1930s',\n",
              "  'end_pos': 23,\n",
              "  'end_score': 6.638422,\n",
              "  'score': 39.274616,\n",
              "  'start_pos': 22,\n",
              "  'start_score': 5.916258}]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_answer_list.to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a-3tnTtuQDY",
        "outputId": "b5867c04-e63c-491c-d333-75ec855af496"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['specialist schools',\n",
              " 'insects',\n",
              " 'Until the 20th century, there was no clear record of the number of Venezuelans who emigrated to the United States.',\n",
              " 'summer of 1934',\n",
              " '1930s']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaulate with official function"
      ],
      "metadata": {
        "id": "65Arp4St3AG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "odaMNuIr3Qgl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data_df = pd.DataFrame(dev_data_dict)\n",
        "dev_feature_df = dev_data_df.apply(lambda df: prepare_feature(df),axis = 1)\n",
        "dev_feature_df = pd.DataFrame(list(dev_feature_df))\n",
        "DevTokenizedDataset  = SQUADTokenizedDataSet(dev_feature_df,\"cuda\")"
      ],
      "metadata": {
        "id": "uCUAODer4GYt"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DevTokenizedLoader = DataLoader(DevTokenizedDataset,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "-n0d6A_m4c0u"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_result_dict_list = []"
      ],
      "metadata": {
        "id": "MnOIPcD35kIl"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token_inputs in tqdm(DevTokenizedLoader):\n",
        "    result_dict_list = answer_question_from_tokenized_inputs(model,token_inputs,device = 'cuda')\n",
        "    all_result_dict_list.extend(result_dict_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u51DT9uE5FVp",
        "outputId": "df9a725d-bbb3-4802-a01e-09b97d5906fd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 372/372 [05:01<00:00,  1.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_answers = [dict_['answer'] for dict_ in all_result_dict_list]"
      ],
      "metadata": {
        "id": "-4m9PC_A5_we"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data_df['prection_answer'] = predict_answers"
      ],
      "metadata": {
        "id": "Xf75j6_A6SeW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = dev_data_df[['id','prection_answer']].set_index('id').T.to_dict('records')[0]"
      ],
      "metadata": {
        "id": "cDgUt2-18pnB"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_dataset = read_json(dev_data_path)"
      ],
      "metadata": {
        "id": "3_AXIeKg6V5O"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# import official evaluation function\n",
        "sys.path.append(squad_v2_dir)"
      ],
      "metadata": {
        "id": "d6M7ISBs07v_"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate as evaluate_utils "
      ],
      "metadata": {
        "id": "8AmQFlgz1Lln"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exact_raw,f1_raw = evaluate_utils.get_raw_scores(dev_dataset,preds)"
      ],
      "metadata": {
        "id": "HZvtLbTy1ozV"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_utils.make_eval_dict(exact_raw,f1_raw)  "
      ],
      "metadata": {
        "id": "-wmcto2a9_Cs"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics\n",
        "# increate the size of training data to imporve the metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1y-IhoJ1pW2",
        "outputId": "9f23b134-883f-439f-8ada-b06d3da92316"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('exact', 27.170891939695107),\n",
              "             ('f1', 33.267882531140515),\n",
              "             ('total', 11873)])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Fine Tune DistilBERT For Question And Answering on SQUAD",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}